---
title: "Assignment 7: GLMs week 2 (Linear Regression and beyond)"
author: "Sierra Kindley"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: console
---

## OVERVIEW

This exercise accompanies the lessons in Environmental Data Analytics on generalized linear models. 

## Directions
1. Change "Student Name" on line 3 (above) with your name.
3. Work through the steps, **creating code and output** that fulfill each instruction.
4. Be sure to **answer the questions** in this assignment document.
6. When you have completed the assignment, **Knit** the text and code into a single PDF file.
8. After Knitting, submit the completed exercise (PDF file) to the dropbox in Sakai. Add your last name into the file name (e.g., "Salk_A06_GLMs_Week1.Rmd") prior to submission.

The completed exercise is due on Tuesday, February 25 at 1:00 pm.

## Set up your session 
1. Set up your session. Check your working directory, load the tidyverse, nlme, and piecewiseSEM packages, import the *raw* NTL-LTER raw data file for chemistry/physics, and import the processed litter dataset. You will not work with dates, so no need to format your date columns this time.

2. Build a ggplot theme and set it as your default theme.

```{r}
#1
getwd() #verify working directory
library(tidyverse) #load tidyverse packages
library(nlme) #load nlme package
library(piecewiseSEM) #load piecewiseSEM package
library(RColorBrewer) #load RColorBrewer package for plot colors
LakeChemData.raw <- 
  read.csv("./Data/Raw/NTL-LTER_Lake_ChemistryPhysics_Raw.csv")
  #import the raw NTL-LTER lake chemistry/physics dataset
Litter.processed <- 
  read.csv("./Data/Processed/NEON_NIWO_Litter_mass_trap_Processed.csv")
  #import the processed litter dataset

#2
sierratheme <- theme_classic(base_size = 14) +
  theme(axis.text = element_text(color = "black"), 
        legend.position = "top")
#build new theme 'sierratheme' and define its parameters
theme_set(sierratheme) #set sierratheme as default plot theme

```


## NTL-LTER test
Research question: What is the best set of predictors for lake temperatures in July across the monitoring period at the North Temperate Lakes LTER? 

3. Wrangle your NTL-LTER dataset with a pipe function so that it contains only the following criteria: 

* Only dates in July (hint: use the daynum column). No need to consider leap years.
* Only the columns: lakename, year4, daynum, depth, temperature_C
* Only complete cases (i.e., remove NAs)

4. Run an AIC to determine what set of explanatory variables (year4, daynum, depth) is best suited to predict temperature. Run a multiple regression on the recommended set of variables. 

```{r}
#3
LakeChemData.raw.filtered <- 
  LakeChemData.raw %>%
  filter(daynum > 181 & daynum < 213) %>% #only select data from dates in July
  select(lakename, year4, daynum, depth, temperature_C) %>% #select only the specified columns
  na.exclude() #remove incomplete cases containing NAs

#4
LakeChemData.AIC <- lm(data = LakeChemData.raw.filtered, temperature_C ~ year4 + daynum + 
                    depth)
step(LakeChemData.AIC) 
#run an AIC to determine variables best suited for predicting temperature
LakesChem.multregression <- lm(data = LakeChemData.raw.filtered, temperature_C ~ year4 + 
                            daynum + depth) #run a multiple regression on recommended variables
summary(LakesChem.multregression)

```

5. What is the final set of explanatory variables that predict temperature from your multiple regression? How much of the observed variance does this model explain?

> Answer: The final set of explanatory variables that predict temperature from my multiple regression include year4, daynum, and depth. Approximately 74.17% of the oberved variance is explained by this model.

6. Run an interaction effects ANCOVA to predict temperature based on depth and lakename from the same wrangled dataset.

```{r}
#6
LakeChem.ancova.interaction <- lm(data = LakeChemData.raw.filtered, 
                                  temperature_C ~ lakename * depth)
#run interaction effects ANCOVA to predict temperature from depth & lakename
summary(LakeChem.ancova.interaction)

```

7. Is there a significant interaction between depth and lakename? How much variance in the temperature observations does this explain?

> Answer: Yes, there is a significant interaction between depth and lakename. This explains approximately 78.57% of the variance in the temperature observations.

8. Create a graph that depicts temperature by depth, with a separate color for each lake. Add a geom_smooth (method = "lm", se = FALSE) for each lake. Make your points 50 % transparent. Adjust your y axis limits to go from 0 to 35 degrees. Clean up your graph to make it pretty. 

```{r}
#8
Lakes.plot <- ggplot(LakeChemData.raw.filtered, 
                     aes(x = depth, y = temperature_C, color = lakename)) + 
  geom_point(alpha = 0.5) + #make points 50% transparent
  geom_smooth(method = "lm", se = FALSE) + #add geom_smooth for each lake
  labs(x = "Depth (m)", y = expression("Temperature " ( degree~C)), color = "") + #axis labels
  scale_color_brewer(palette = "Paired") + #define color palette
  ylim(0,35) #define y-axis limits
print(Lakes.plot)

```

9. Run a mixed effects model to predict dry mass of litter. We already know that nlcdClass and functionalGroup have a significant interaction, so we will specify those two variables as fixed effects with an interaction. We also know that litter mass varies across plot ID, but we are less interested in the actual effect of the plot itself but rather in accounting for the variance among plots. Plot ID will be our random effect.

a. Build and run a mixed effects model.
b. Check the difference between the marginal and conditional R2 of the model. 

```{r}

LitterTest.mixed <- lme(data = Litter.processed,
                     dryMass ~ nlcdClass * functionalGroup,
                     random = ~1|plotID)
#run mixed effects model to predict dry mass with nlcdClass and functionalGroup
#as fixed effects w/ interaction and plotID as a random effect
summary(LitterTest.mixed)
rsquared(LitterTest.mixed) #check marginal & conditional R^2 values of model

```

b. continued... How much more variance is explained by adding the random effect to the model? 

> Answer: Approximately 2% more variance is explained by adding the random effect to the model.

c. Run the same model without the random effect.
d. Run an anova on the two tests. 
```{r}

LitterTest.fixed <- gls(data = Litter.processed,
                      dryMass ~ nlcdClass * functionalGroup)
#run fixed effects model to predict dry mass with nlcdClass and functionalGroup
#as fixed effects w/ interaction (no random effects included)
summary(LitterTest.fixed)
rsquared(LitterTest.fixed) #check R^2 value of the model

anova(LitterTest.mixed, LitterTest.fixed) #run ANOVA on mixed & fixed tests

```

d. continued... Is the mixed effects model a better model than the fixed effects model? How do you know?

> Answer: Yes, the mixed effects model (with the random effect included) is a better model than the fixed effects model (with no random effect), as it is able to explain a (slightly) larger percentage of the variance in the data and yields a (slightly) lower AIC value. The fact that the p-value of the ANOVA (run in part 9d) is less than the significance level indicates that we can reject the null hypothesis and say that there is, indeed, a statistically significant difference in the fit of the two models.